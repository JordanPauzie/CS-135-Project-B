{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('/Users/brandonmukadziwashe/CS135/cs135-24f-assignments/CS-135-Project-B/data_movie_lens_100k/movie_info.csv')\n",
    "ratings_df = pd.read_csv('/Users/brandonmukadziwashe/CS135/cs135-24f-assignments/CS-135-Project-B/data_movie_lens_100k/ratings_all_development_set.csv')\n",
    "# print(movies_df)\n",
    "# Rename columns\n",
    "ratings_df = ratings_df.rename(columns={'user_id': 'userId', 'item_id': 'movieId'})\n",
    "movies_df = movies_df.rename(columns={'item_id': 'movieId'})\n",
    "leaderboard_data = pd.read_csv('/Users/brandonmukadziwashe/CS135/cs135-24f-assignments/CS-135-Project-B/data_movie_lens_100k/ratings_masked_leaderboard_set.csv')  # Replace with your leaderboard file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 2.9621 - val_loss: 0.8340\n",
      "Epoch 2/6\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7808 - val_loss: 0.7654\n",
      "Epoch 3/6\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7086 - val_loss: 0.7481\n",
      "Epoch 4/6\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6706 - val_loss: 0.7428\n",
      "Epoch 5/6\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6277 - val_loss: 0.7409\n",
      "Epoch 6/6\n",
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5815 - val_loss: 0.7447\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.7420\n",
      "Test loss (MAE): 0.7409058809280396\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step\n",
      "Predictions for user 772, ordered by closest rating difference:\n",
      "       original_user_id  original_movie_id  actual_rating  predicted_rating  \\\n",
      "8138                772                431              3          3.264826   \n",
      "76753               772                230              2          2.315729   \n",
      "67026               772                893              2          2.437840   \n",
      "89249               772                391              2          2.457989   \n",
      "525                 772                175              4          3.541944   \n",
      "13524               772                565              2          2.617497   \n",
      "74901               772                187              3          3.653527   \n",
      "10398               772                946              2          1.289227   \n",
      "44904               772                 69              3          3.807497   \n",
      "62191               772                917              5          4.186271   \n",
      "74708               772                126              5          4.163712   \n",
      "38949               772                 95              2          2.881770   \n",
      "19940               772               1019              5          4.091374   \n",
      "56211               772                170              5          4.073076   \n",
      "21632               772                284              3          3.987595   \n",
      "70790               772               1034              3          1.919101   \n",
      "26294               772                401              2          3.086750   \n",
      "89978               772                728              3          4.105055   \n",
      "71188               772                183              2          3.248415   \n",
      "78013               772                257              5          3.426164   \n",
      "63078               772                180              5          3.198806   \n",
      "57334               772                  6              2          4.000050   \n",
      "89032               772                922              1          3.236331   \n",
      "\n",
      "       rating_difference  \n",
      "8138            0.264826  \n",
      "76753           0.315729  \n",
      "67026           0.437840  \n",
      "89249           0.457989  \n",
      "525             0.458056  \n",
      "13524           0.617497  \n",
      "74901           0.653527  \n",
      "10398           0.710773  \n",
      "44904           0.807497  \n",
      "62191           0.813729  \n",
      "74708           0.836288  \n",
      "38949           0.881770  \n",
      "19940           0.908626  \n",
      "56211           0.926924  \n",
      "21632           0.987595  \n",
      "70790           1.080899  \n",
      "26294           1.086750  \n",
      "89978           1.105055  \n",
      "71188           1.248415  \n",
      "78013           1.573836  \n",
      "63078           1.801194  \n",
      "57334           2.000050  \n",
      "89032           2.236331  \n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ensure required columns exist\n",
    "assert 'userId' in ratings_df.columns and 'movieId' in ratings_df.columns and 'rating' in ratings_df.columns\n",
    "\n",
    "# Encode user and movie IDs\n",
    "user_encoder = LabelEncoder()\n",
    "ratings_df['user_id_encoded'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "\n",
    "movie_encoder = LabelEncoder()\n",
    "ratings_df['movie_id_encoded'] = movie_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "# Copy the dataset and split into train and test sets\n",
    "df = ratings_df.copy()\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert columns to NumPy arrays\n",
    "train_user_ids = np.array(train['user_id_encoded'].values)\n",
    "train_movie_ids = np.array(train['movie_id_encoded'].values)\n",
    "train_ratings = np.array(train['rating'].values)\n",
    "\n",
    "test_user_ids = np.array(test['user_id_encoded'].values)\n",
    "test_movie_ids = np.array(test['movie_id_encoded'].values)\n",
    "test_ratings = np.array(test['rating'].values)\n",
    "\n",
    "# Define the number of unique users, movies, and embedding dimensions\n",
    "num_users = df['user_id_encoded'].nunique()\n",
    "num_movies = df['movie_id_encoded'].nunique()\n",
    "embedding_dim = 50\n",
    "\n",
    "# Define the model\n",
    "# User input and embedding\n",
    "user_input = Input(shape=(1,), name='user_input')\n",
    "user_embedding = Embedding(input_dim=num_users, output_dim=embedding_dim, name='user_embedding')(user_input)\n",
    "user_embedding = Flatten()(user_embedding)\n",
    "\n",
    "# Movie input and embedding\n",
    "movie_input = Input(shape=(1,), name='movie_input')\n",
    "movie_embedding = Embedding(input_dim=num_movies, output_dim=embedding_dim, name='movie_embedding')(movie_input)\n",
    "movie_embedding = Flatten()(movie_embedding)\n",
    "\n",
    "# Dot product of embeddings and output layer\n",
    "dot_product = Dot(axes=1)([user_embedding, movie_embedding])\n",
    "output = Dense(1, activation='linear')(dot_product)\n",
    "\n",
    "# Compile the model\n",
    "model2 = Model(inputs=[user_input, movie_input], outputs=output)\n",
    "model2.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "# Add early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(\n",
    "    [train_user_ids, train_movie_ids], train_ratings,\n",
    "    epochs=6,\n",
    "    batch_size=64,\n",
    "    validation_data=([test_user_ids, test_movie_ids], test_ratings),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss = model2.evaluate([test_user_ids, test_movie_ids], test_ratings)\n",
    "print(f\"Test loss (MAE): {test_loss}\")\n",
    "\n",
    "# Predict ratings for the test set\n",
    "test_predictions = model2.predict([test_user_ids, test_movie_ids])\n",
    "\n",
    "# Create a DataFrame with predictions\n",
    "test_results = pd.DataFrame({\n",
    "    'original_user_id': test['userId'],\n",
    "    'original_movie_id': test['movieId'],\n",
    "    'actual_rating': test_ratings,\n",
    "    'predicted_rating': test_predictions.flatten()\n",
    "})\n",
    "test_results['rating_difference'] = abs(test_results['actual_rating'] - test_results['predicted_rating'])\n",
    "\n",
    "# Filter results for a specific user and sort by rating difference\n",
    "filter_user_id = 772  # Replace with your desired user ID\n",
    "filtered_results = test_results[test_results['original_user_id'] == filter_user_id]\n",
    "filtered_results_sorted = filtered_results.sort_values(by='rating_difference')\n",
    "\n",
    "print(f\"Predictions for user {filter_user_id}, ordered by closest rating difference:\")\n",
    "print(filtered_results_sorted)\n",
    "\n",
    "# Load leaderboard data\n",
    "leaderboard_data = pd.read_csv('/Users/brandonmukadziwashe/CS135/cs135-24f-assignments/CS-135-Project-B/data_movie_lens_100k/ratings_masked_leaderboard_set.csv')  # Replace with your leaderboard file path\n",
    "assert 'user_id' in leaderboard_data.columns and 'item_id' in leaderboard_data.columns\n",
    "\n",
    "# Handle unseen user and movie IDs using mapping\n",
    "user_mapping = dict(zip(user_encoder.classes_, user_encoder.transform(user_encoder.classes_)))\n",
    "movie_mapping = dict(zip(movie_encoder.classes_, movie_encoder.transform(movie_encoder.classes_)))\n",
    "\n",
    "leaderboard_data['user_id_encoded'] = leaderboard_data['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "leaderboard_data['item_id_encoded'] = leaderboard_data['item_id'].map(movie_mapping).fillna(-1).astype(int)\n",
    "\n",
    "# Predict leaderboard ratings, handling valid IDs only\n",
    "user_ids = leaderboard_data['user_id_encoded'].values\n",
    "item_ids = leaderboard_data['item_id_encoded'].values\n",
    "\n",
    "valid_indices = (user_ids != -1) & (item_ids != -1)\n",
    "predictions = np.full(len(user_ids), np.nan)  # Initialize with NaN\n",
    "predictions[valid_indices] = model2.predict([user_ids[valid_indices], item_ids[valid_indices]]).flatten()\n",
    "\n",
    "# Save leaderboard predictions to a file\n",
    "with open(\"predicted_ratings_leaderboard3.txt\", \"w\") as f:\n",
    "    for pred in predictions:\n",
    "        if np.isnan(pred):  # Handle invalid predictions\n",
    "            f.write(\"Invalid\\n\")\n",
    "        else:\n",
    "            f.write(f\"{pred}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
